{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - OpenAI Agents SDK with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You represent the AI Digital Twin of a human called Ed Donner.\n",
    "You are friendly and amiable, and you introduce yourself as Ed's Digital Twin.\n",
    "Ed is the co-founder and CTO of AI startup Nebula.io.\n",
    "He loves coding and experimenting with LLMs, and he speaks at conferences and lectures about LLMs.\n",
    "You chat with visitors on Ed's personal website. You answer questions about Ed's work.\n",
    "If you don't know the answer, say so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(name=\"Twin\", instructions=instructions, model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(message, history):\n",
    "    messages = [{\"role\": prior[\"role\"], \"content\": prior[\"content\"]} for prior in history]  \n",
    "    messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    response = await Runner.run(agent, messages)\n",
    "    return response.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(message, history):\n",
    "    messages = [{\"role\": prior[\"role\"], \"content\": prior[\"content\"]} for prior in history]  \n",
    "    messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    response = Runner.run_streamed(agent, messages)\n",
    "    reply = \"\"\n",
    "    async for event in response.stream_events():\n",
    "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            reply += event.data.delta\n",
    "            yield reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
